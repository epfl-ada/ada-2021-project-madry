{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfa19caa-6437-4f16-b6d5-01347159d330",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e447f2f-9f8e-4398-aaf6-21b33ef3ea41",
   "metadata": {},
   "source": [
    "The preprocessing pipeline should output a list of speakers with quotes. Each element of this list should contain information about the speaker (full name, gender, date of birth...) - obtained from wikidata, and a string formed by joining multiple quotes in order to get a string of fixed length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80871718-bd1a-4806-b4be-c75f898ecc9a",
   "metadata": {},
   "source": [
    "The pipeline is presented through a data analysis example - analysing the personalities of the US politicians. In this example we take 100 politicians from both of the two major political parties, the Democratic party and the Republican party. We select the politicians which have the most quotes in our database. We only consider quotes for which the probability of the speaker is higher than 80% (referenced as significant quotes in this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1bab713-bee5-46eb-a26f-446db88ac641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import bz2\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d57b92-b15c-4f8e-8195-cfd3a7669877",
   "metadata": {},
   "source": [
    "### Counting significant quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08fdb05-f8e7-42fb-9f2b-2f00a60bde59",
   "metadata": {},
   "source": [
    "<b>This step has been executed once and will not be needed in following analyses since the quote counts calculated are for all the speakers and the output can be simply reused.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f263f01-5c14-48e6-8cfb-c6b813e17cb4",
   "metadata": {},
   "source": [
    "Define some methods for better reusability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d02c4c6-18f0-4fbe-b387-a6fa98151145",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN_INPUT = \"../quotebank/quotes-{}.json.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d36977-e339-4f1e-bfcd-85c0e38b86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_to_file(name, obj):\n",
    "    # Use current timestamp to make the name of the file unique\n",
    "    millis = round(time.time() * 1000)\n",
    "    name = f'{name}_{millis}.json'\n",
    "    with open(name, 'wb') as f:\n",
    "        output = json.dumps(obj)\n",
    "        f.write(output.encode('utf-8'))\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51a096f-ec25-4b33-b006-dc2afc478a0a",
   "metadata": {},
   "source": [
    "Method used for counting significant quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e0b1b4-2039-4712-ab88-266837c01038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_significant_quote(row: dict, significant_quote_counters: dict) -> None:\n",
    "    \"\"\"Check if the quote for a given row can be considered significant for analysis and update\n",
    "    the significancy dictionary.\n",
    "\n",
    "    Args:\n",
    "        row (dict): Row of data\n",
    "        significant_quote_counters (dict): Dict to keep track of significant quotes\n",
    "    \"\"\"\n",
    "    probabilities = row['probas']\n",
    "    qids = row['qids']\n",
    "    \n",
    "    # Check if the probas and qids values exist\n",
    "    if (len(probabilities) == 0 or len(qids) == 0):\n",
    "        return\n",
    "    \n",
    "    # Check if the speaker is not 'Unknown'\n",
    "    if (probabilities[0][0] == 'None'):\n",
    "        return\n",
    "    \n",
    "    # Check if the probability is over 80%\n",
    "    prob = float(probabilities[0][1])\n",
    "    if (prob < 0.8):\n",
    "        return\n",
    "    \n",
    "    # Increment count\n",
    "    qid = qids[0]\n",
    "    significant_quote_counters[qid] = significant_quote_counters.get(qid, 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d915fd-fc0e-4ed3-b3da-590afc1e309c",
   "metadata": {},
   "source": [
    "General method used for processing the quotes files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5585ef73-71f2-4f37-bf72-43df24a94dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "CHUNK_SIZE = 1_048_576\n",
    "\n",
    "def process_compressed_json_file(input_file_name: str, output_name: str, year: int, process_json_object: Callable) -> str:\n",
    "    \"\"\"\n",
    "    Read from a compressed file chunk by chunk. Decompress every chunk and try to decode it and parse it into an array of JSON objects.\n",
    "    For each JSON object extracted this way, run the process_json_object function.\n",
    "    In the end, a JSON object representing the result of this process is written into a file.\n",
    "\n",
    "    Args:\n",
    "        input_file_name (str): Name of the compressed json file which is the subject of processing.\n",
    "        output_name (str): First part of the output file name. Used in creation of the full output file name: the year parameter and a timestamp are appended, as well as the .json extension.\n",
    "        year (int): Represents the year for which the data in the input file is gathered, is appended to the output_name to generate the full output file name.\n",
    "        process_json_object (Callable): Function that processes the individual JSON objects extracted from the compressed file. The signature should be as follows:\n",
    "            Args:\n",
    "                json_obj: JSON object which is to be processed.\n",
    "                out_json: The output object in which the result of the processing is stored\n",
    "\n",
    "    Returns:\n",
    "        (str) Full name of the output JSON file.\n",
    "    \"\"\"\n",
    "    # Decompression variables\n",
    "    decompressor = bz2.BZ2Decompressor()\n",
    "    \n",
    "    # Decoding variables\n",
    "    decoding_buffer = bytearray([])\n",
    "    decoding_error_counter = 0\n",
    "    \n",
    "    # Parsing variables\n",
    "    parsing_buffer = ''\n",
    "    parsing_error_counter = 0\n",
    "    \n",
    "    # Progress variables - used to provide feedback to the dev\n",
    "    input_size = os.path.getsize(input_file_name)\n",
    "    start_time = time.time()\n",
    "    total_in = 0\n",
    "    total_out = 0\n",
    "    previous_value = -1\n",
    "    \n",
    "    # Result of processing\n",
    "    out_json = dict()\n",
    "    \n",
    "    # Iterate through the file\n",
    "    with open(input_file_name, 'rb') as input_file:\n",
    "        for chunk in iter(lambda: input_file.read(CHUNK_SIZE), b''):\n",
    "            # Feed chunk to decompressor\n",
    "            decompressed_chunk = decompressor.decompress(chunk)\n",
    "            dec_chunk_length = len(decompressed_chunk)\n",
    "            \n",
    "            # Check the length of the decompressed data - 0 is common -- waiting for a bzip2 block\n",
    "            if (dec_chunk_length == 0):\n",
    "                continue\n",
    "            \n",
    "            # Try to decode byte array\n",
    "            decoding_buffer += decompressed_chunk\n",
    "            try:\n",
    "                chunk_string = decoding_buffer.decode('utf-8')\n",
    "                \n",
    "                # Clear buffer\n",
    "                decoding_buffer = bytearray([])\n",
    "                \n",
    "                decoding_successful = True\n",
    "            except UnicodeDecodeError:\n",
    "                # Error occurs when input stream is split in the middle of a character which is encoded with multiple bytes\n",
    "                decoding_error_counter += 1\n",
    "                decoding_successful = False\n",
    "            \n",
    "            # Try to parse the decoded string\n",
    "            if decoding_successful:\n",
    "                # Elements of the JSON array are split by '\\n'\n",
    "                array_elements = chunk_string.split('\\n')\n",
    "                \n",
    "                # Iterate through the JSON array in the current chunk\n",
    "                for json_candidate in array_elements:\n",
    "                    # Try to parse the JSON object, might fail if the object was divided in parts because of the chunk separation\n",
    "                    parsing_buffer += json_candidate\n",
    "                    try:\n",
    "                        json_obj = json.loads(parsing_buffer)\n",
    "                        \n",
    "                        # Clear buffer\n",
    "                        parsing_buffer = ''\n",
    "                        \n",
    "                        parsing_successful = True\n",
    "                    except ValueError:\n",
    "                        \"\"\"\n",
    "                        Error occurs when the line does not contain the whole JSON object, which happens for the last array element in almost every chunk of input stream.\n",
    "                        We solve this by remembering the prevous partial objects in parsing_buffer, and then merging it with the rest of the object when we load the next chunk.\n",
    "                        \"\"\"\n",
    "                        parsing_error_counter += 1\n",
    "                        parsing_successful = False\n",
    "                    \n",
    "                    # Perform JSON object processing\n",
    "                    if parsing_successful:\n",
    "                        process_json_object(json_obj, out_json)\n",
    "            \n",
    "            # Show progress\n",
    "            total_in += len(chunk)\n",
    "            total_out += dec_chunk_length\n",
    "            if dec_chunk_length != 0:    # only if a bzip2 block emitted\n",
    "                processed_fraction = round(1000 * total_in / input_size)\n",
    "                if processed_fraction != previous_value:\n",
    "                    left = (input_size / total_in - 1) * (time.time() - start_time)\n",
    "                    print(f'\\r{processed_fraction / 10:.1f}% (~{left:.1f}s left)\\tyear: {year}\\tnumber of entries: {len(out_json)}\\tdecoding errors: {decoding_error_counter}\\tparsing errors: {parsing_error_counter}', end='      ')\n",
    "                    previous_value = processed_fraction\n",
    "    \n",
    "    # Save result to file\n",
    "    output_full_name = write_json_to_file(f'{output_name}-{year}', out_json)\n",
    "    \n",
    "    # Report ending\n",
    "    print()\n",
    "    total_time = time.time() - start_time\n",
    "    print(f'File {input_file_name} processed in {total_time:.1f}s', end='\\n\\n')\n",
    "    \n",
    "    return output_full_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7328f060-7f5b-49d3-94b8-a9633427bd5e",
   "metadata": {},
   "source": [
    "Create files for every year, each file contains a dictionary where the key is the QID of the speaker, and the value is the number of significant quotes.\n",
    "<br><br>\n",
    "<font color='red'>WARNING: LONG EXECUTION!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53983251-4b96-42de-8402-99ed7afe337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
    "# years = [2020]\n",
    "\n",
    "output_list = []\n",
    "\n",
    "for year in years:\n",
    "    path_to_input = PATTERN_INPUT.format(year)\n",
    "    \n",
    "    # Process quote file\n",
    "    output_name = process_compressed_json_file(path_to_input, 'data/signi-quote-count', year, check_if_significant_quote)\n",
    "    \n",
    "    output_list.append(output_name)\n",
    "\n",
    "print('\\n\\nOutput file names:')\n",
    "for file_name in output_list:\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b13ee-41a4-4d9e-969b-ee949ebe30f9",
   "metadata": {},
   "source": [
    "Now combine the quote counts into a single file.\n",
    "<br>\n",
    "An example of the file names is used, the string should be updated if the code is run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88727e52-19fb-447a-b0a4-653582d13d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "signi_quotes_file_names = [\n",
    "    \"../quotebank/signi-quote-count-2015_1636244638891.json\",\n",
    "    \"../quotebank/signi-quote-count-2016_1636246832187.json\",\n",
    "    \"../quotebank/signi-quote-count-2017_1636249273913.json\",\n",
    "    \"../quotebank/signi-quote-count-2018_1636250518608.json\",\n",
    "    \"../quotebank/signi-quote-count-2019_1636251729971.json\",\n",
    "    \"../quotebank/signi-quote-count-2020_1636237785105.json\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b0d00c-0663-476f-ad5d-f6afd69dee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_signi_dict = {}\n",
    "\n",
    "for file_name in signi_quotes_file_names:\n",
    "    with open(file_name, 'r') as f:\n",
    "        one_dict = json.load(f)\n",
    "        for k in one_dict.keys():\n",
    "            combined_signi_dict[k] = combined_signi_dict.get(k, 0) + one_dict[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be4708-858b-49fd-82c6-9437d0cf463a",
   "metadata": {},
   "source": [
    "Sort the dictionary so the speakers with the most quotes appear first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df134db-4833-4b14-b179-9e8070e3bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_combined_signi_dict = {k: v for k, v in sorted(combined_signi_dict.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5cf729-0697-4a88-94b3-8faf7cd737b1",
   "metadata": {},
   "source": [
    "And finally save the resulting dictionary into a file, this file can later be reused for multiple analyses, whenever we need to choose a representation of a group of people using the number of quotes to pick the most quoted individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeabe2a1-4436-45b9-be62-df9fd8069e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/signi-quote-count-combined_1636658426963.json'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_json_to_file('data/signi-quote-count-combined', sorted_combined_signi_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb8080a-75fd-42a7-a3d9-057401e7f8d2",
   "metadata": {},
   "source": [
    "Display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4baaf6a7-5b3c-4a75-b44e-519cfc043d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Number of quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q22686</td>\n",
       "      <td>201293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1058</td>\n",
       "      <td>76404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q76</td>\n",
       "      <td>59650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q450675</td>\n",
       "      <td>37218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q83106</td>\n",
       "      <td>33025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Number of quotes\n",
       "0   Q22686            201293\n",
       "1    Q1058             76404\n",
       "2      Q76             59650\n",
       "3  Q450675             37218\n",
       "4   Q83106             33025"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sorted_combined_signi_dict.items(), columns=['ID', 'Number of quotes']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12018aae-3a5a-48a0-9e74-12f0a21763a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get the wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f674fda1-e30d-4499-8588-6d1e1092fbe3",
   "metadata": {},
   "source": [
    "We used the https://query.wikidata.org/ website to get the relevant wikidata. The SPARQL query is in the following cell.\n",
    "<br>\n",
    "We can do this (and did do afterwards) using the provided wikidata parquet file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fdae69-d7cd-4cff-abdf-3ea75079f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT DISTINCT ?item ?itemLabel \n",
    "          ?genderLabel ?citizenshipLabel ?languageLabel ?religionLabel ?ethnicLabel ?degreeLabel\n",
    "          ?dateOfBirth ?placeOfBirthLabel \n",
    "#           ?nativeNameLabel ?birthNameLabel ?givenNameLabel ?familyNameLabel ?pseudonymLabel \n",
    "#           ?fatherLabel ?motherLabel ?siblingLabel ?spouseLabel ?childLabel ?numOfChild \n",
    "#           ?occupationLabel ?positionLabel ?ideologyLabel ?educatedAtLabel\n",
    "          ?memberOfParty ?memberOfPartyLabel \n",
    "WHERE {\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE]\". }\n",
    "  {\n",
    "    ?item p:P106 ?statement0.\n",
    "    ?statement0 (ps:P106) wd:Q82955.\n",
    "    {\n",
    "      ?item p:P102 ?statement1.\n",
    "      ?statement1 (ps:P102) wd:Q29552.\n",
    "    }\n",
    "    UNION\n",
    "    {\n",
    "      ?item p:P102 ?statement2.\n",
    "      ?statement2 (ps:P102) wd:Q29468.\n",
    "    }\n",
    "    MINUS {\n",
    "      ?item p:P570 ?statement_3.\n",
    "      ?statement_3 psv:P570 ?statementValue_3.\n",
    "      ?statementValue_3 wikibase:timePrecision ?precision_3.\n",
    "      FILTER(?precision_3 >= 11 )\n",
    "      ?statementValue_3 wikibase:timeValue ?P570_3.\n",
    "      FILTER(?P570_3 < \"+2015-01-01T00:00:00Z\"^^xsd:dateTime)\n",
    "    }\n",
    "    OPTIONAL { ?item wdt:P21 ?gender. }\n",
    "    OPTIONAL { ?item wdt:P27 ?citizenship. }\n",
    "    OPTIONAL { ?item wdt:P103 ?language. }\n",
    "    OPTIONAL { ?item wdt:P140 ?religion. }\n",
    "    OPTIONAL { ?item wdt:P172 ?ethnic. }\n",
    "    OPTIONAL { ?item wdt:P512 ?degree. }\n",
    "    \n",
    "    OPTIONAL { ?item wdt:P569 ?dateOfBirth. }\n",
    "    OPTIONAL { ?item wdt:P19 ?placeOfBirth. }\n",
    "    \n",
    "#     OPTIONAL { ?item wdt:P1559 ?nativeName. }\n",
    "#     OPTIONAL { ?item wdt:P1477 ?birthName. }\n",
    "#     OPTIONAL { ?item wdt:P735 ?givenName. }\n",
    "#     OPTIONAL { ?item wdt:P734 ?familyName. }\n",
    "#     OPTIONAL { ?item wdt:P742 ?pseudonym. }\n",
    "    \n",
    "#     OPTIONAL { ?item wdt:P22 ?father. }\n",
    "#     OPTIONAL { ?item wdt:P25 ?mother. }\n",
    "#     OPTIONAL { ?item wdt:P3373 ?sibling. }\n",
    "#     OPTIONAL { ?item wdt:P26 ?spouse. }\n",
    "#     OPTIONAL { ?item wdt:P40 ?child. }\n",
    "#     OPTIONAL { ?item wdt:P1971 ?numOfChild. }\n",
    "    \n",
    "#     OPTIONAL { ?item wdt:P106 ?occupation. }\n",
    "#     OPTIONAL { ?item wdt:P39 ?position. }\n",
    "#     OPTIONAL { ?item wdt:P1142 ?ideology. }\n",
    "#     OPTIONAL { ?item wdt:P69 ?educatedAt. }\n",
    "    \n",
    "    OPTIONAL { ?item wdt:P102 ?memberOfParty. }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d7475f-fb4d-4f46-9b9e-704f22e7631e",
   "metadata": {},
   "source": [
    "Merge duplicate objects representing a single speaker but with differing fields.\n",
    "<br>\n",
    "Example: Arnold Schwarzenegger has both Austrian and American nationalities, and would appear twice, once with Austrian, and once with American nationality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fbda022-cad4-42ec-9715-18a6a7e346ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../quotebank/american_politicians_fixed.json\", \"r\") as f:\n",
    "    wiki_poli = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c56b066b-505e-48a5-811f-de907c067193",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_poli_merged = dict()\n",
    "\n",
    "index = 0\n",
    "for row in wiki_poli:\n",
    "    # Extract the QID from the link (ex. http://www.wikidata.org/entity/Q203286 -> Q203286)\n",
    "    qid_start = row['item'].rindex('/') + 1\n",
    "    key = row['item'][qid_start:]\n",
    "    # Replace the link with the QID\n",
    "    row['item'] = key\n",
    "    \n",
    "    if key in wiki_poli_merged:\n",
    "        merged_entry = wiki_poli_merged[key]\n",
    "        columns = ['itemLabel', 'genderLabel', 'citizenshipLabel', 'religionLabel', 'ethnicLabel', 'degreeLabel', 'dateOfBirth', 'placeOfBirthLabel', 'memberOfParty', 'memberOfPartyLabel', 'languageLabel']\n",
    "        \"\"\"\n",
    "        Merge the values for every column:\n",
    "            - if the values are the same - do nothing\n",
    "            - if the values are different - create a list and add them both\n",
    "        \"\"\"\n",
    "        for col in columns:\n",
    "            if row.get(col, None) is None:\n",
    "                continue\n",
    "                \n",
    "            updated_entry = merged_entry.get(col, None)\n",
    "            \n",
    "            if updated_entry is None:\n",
    "                updated_entry = row[col]\n",
    "            elif isinstance(updated_entry, list):\n",
    "                if row[col] not in updated_entry:\n",
    "                    updated_entry.append(row[col])\n",
    "            elif row[col] != updated_entry:\n",
    "                updated_entry = [updated_entry, row[col]]\n",
    "                \n",
    "            merged_entry[col] = updated_entry\n",
    "    else:\n",
    "        wiki_poli_merged[key] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b884918a-8b0f-46bf-a9fc-6c28a0f48645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/american_politicians_final_1636658463095.json'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_json_to_file('data/american_politicians_final', wiki_poli_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce040a-e05a-42ea-94c0-34882505d9fa",
   "metadata": {},
   "source": [
    "Alternatively, we can query the wikidata parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55846ac1-6515-4f5e-b5f2-ae3fdfa9b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = pd.read_parquet('data/speaker_attributes.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93c18a8e-0156-4613-bcb0-a25a47869051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import to_datetime\n",
    "import datetime\n",
    "\n",
    "DEMOCRATIC_PARTY_QID = 'Q29552'\n",
    "REPUBLICAN_PARTY_QID = 'Q29468'\n",
    "POLITICIAN_QID = 'Q82955'\n",
    "party_match = speakers.party.apply(lambda p: DEMOCRATIC_PARTY_QID in p or REPUBLICAN_PARTY_QID in p if p is not None else False)\n",
    "occupation_match = speakers.occupation.apply(lambda o: POLITICIAN_QID in o if o is not None else False)\n",
    "dob_match = speakers.date_of_birth.apply(lambda d: to_datetime(d[0]) > datetime.date(1900, 1, 1) if d is not None else False)\n",
    "american_politicians = speakers[party_match & occupation_match & dob_match]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd764808-8bd5-4cf4-8a4c-979a45fe8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "american_politicians.to_json('data/american_politicans_parquet.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "25e31d39-a174-4e4a-8a84-e6c800373eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_poli_parquet = json.loads(american_politicians.to_json(orient='records'))\n",
    "\n",
    "wiki_poli_merged = dict()\n",
    "for poli in wiki_poli_parquet:\n",
    "    wiki_poli_merged[poli['id']] = poli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb4e4a-00d7-461d-a6ee-0fcc4d85d707",
   "metadata": {},
   "source": [
    "### Get the 100 most quoted party members"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c17cd2e-0646-4175-971f-68f6f3e24d90",
   "metadata": {},
   "source": [
    "Using the results of the previous two steps - the number of quotes for each speaker, and the list of US politicians, we can compile a list of 100 most quoted members of the two major US political parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2e228fe3-ebfd-4803-b998-54c2be188e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_list = []\n",
    "rep_list = []\n",
    "\n",
    "CAP_TARGET = 100\n",
    "DEM_PARTY = 'Q29552'\n",
    "REP_PARTY = 'Q29468'\n",
    "\n",
    "for v in sorted_combined_signi_dict:\n",
    "    row = wiki_poli_merged.get(v, None)\n",
    "    \n",
    "    # Could not find person in the politician dictionary\n",
    "    if row is None:\n",
    "        continue\n",
    "    \n",
    "    # Get party membership\n",
    "    memberOfParty = row.get('party', None)\n",
    "    if memberOfParty is None:\n",
    "        continue\n",
    "    \n",
    "    # Cast to one element list if not already a list\n",
    "    if isinstance(memberOfParty, list) == False:\n",
    "        memberOfParty = [memberOfParty]\n",
    "    \n",
    "    # Check membership - might have been a member of both during their life\n",
    "    dem_index = -1\n",
    "    if DEM_PARTY in memberOfParty:\n",
    "        dem_index = memberOfParty.index(DEM_PARTY)\n",
    "    \n",
    "    rep_index = -1\n",
    "    if REP_PARTY in memberOfParty:\n",
    "        rep_index = memberOfParty.index(REP_PARTY)\n",
    "    \n",
    "    if (dem_index > -1 and (rep_index == -1 or dem_index < rep_index)):\n",
    "        # Check if the list is already at full capacity\n",
    "        if len(dem_list) < CAP_TARGET:\n",
    "            dem_list.append(row)\n",
    "    elif (rep_index > -1 and (dem_index == -1 or rep_index < dem_index)):\n",
    "        # Check if the list is already at full capacity\n",
    "        if len(rep_list) < CAP_TARGET:\n",
    "            rep_list.append(row)\n",
    "    \n",
    "    # Check if both lists are at full capacity\n",
    "    if len(dem_list) == CAP_TARGET and len(rep_list) == CAP_TARGET:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f645cea4-3877-4bd0-a6c8-6756deb11581",
   "metadata": {},
   "source": [
    "Display the list of politicians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "79c13053-5b17-4068-ad3c-e32e1437b214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    Democratic party members                                       Republican party members                                      \u001b[0m\n",
      "\u001b[1m    Name                           ID         Number of quotes     Name                           ID         Number of quotes    \u001b[0m\n",
      "  1 Barack Obama                   Q76        59650                Donald Trump                   Q22686     201293    \n",
      "  2 Hillary Clinton                Q6294      28126                Mike Pompeo                    Q473239    19402     \n",
      "  3 Bernie Sanders                 Q359442    27652                Lindsey Graham                 Q22212     17352     \n",
      "  4 Nancy Pelosi                   Q170581    20783                Mike Pence                     Q24313     16511     \n",
      "  5 Andrew Cuomo                   Q11673     20165                Mitch McConnell                Q355522    16057     \n",
      "  6 Chuck Schumer                  Q380900    18489                Marco Rubio                    Q324546    15876     \n",
      "  7 Joe Biden                      Q6279      17946                Ted Cruz                       Q2036942   15728     \n",
      "  8 Bill de Blasio                 Q4911497   16996                John McCain                    Q10390     11362     \n",
      "  9 Elizabeth Warren               Q434706    16937                Jeff Sessions                  Q358443    11176     \n",
      " 10 John Kerry                     Q22316     12973                Nikki Haley                    Q11668     10801     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'\n",
    "print(BOLD + f'{\"\":3} {\"Democratic party members\":62} {\"Republican party members\":62}' + END)\n",
    "print(BOLD + f'{\"\":3} {\"Name\":30} {\"ID\":10} {\"Number of quotes\":20} {\"Name\":30} {\"ID\":10} {\"Number of quotes\":20}' + END)\n",
    "\n",
    "for index in range(10):\n",
    "    dem = dem_list[index]\n",
    "    rep = rep_list[index]\n",
    "    \n",
    "    demv = dem['label']\n",
    "    demq = dem['id']\n",
    "    demc = str(sorted_combined_signi_dict.get(demq, -1))\n",
    "    \n",
    "    repv = rep['label']\n",
    "    repq = rep['id']\n",
    "    repc = str(sorted_combined_signi_dict.get(repq, -1))\n",
    "    \n",
    "    print(f\"{index + 1:3} {demv:30} {demq:10} {demc:20} {repv:30} {repq:10} {repc:10}\")\n",
    "    \n",
    "    index += 1\n",
    "    if index % 10 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f8832-5908-449a-aa39-f54b5e35e629",
   "metadata": {},
   "source": [
    "### Get the politician quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144fa20f-4433-498f-bd8b-bc2d9580293a",
   "metadata": {},
   "source": [
    "For the politicians in the previously compiled lists, we now fetch the quotes from the quote files. We use the methods defined at the top of this notebook, which were written in a reusable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3cb0a9b-3e5a-4fd4-bccc-a005c4dde7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_party_member_quote(row: dict, party_member_quotes: dict, party_list: list) -> None:\n",
    "    \"\"\"CHeck if party member quote is useful for analysis\n",
    "\n",
    "    Args:\n",
    "        row (dict): Row of data\n",
    "        party_member_quotes (dict): Dict to keep track of party member quotes\n",
    "        party_list (list): Party list\n",
    "    \"\"\"\n",
    "    probabilities = row['probas']\n",
    "    qids = row['qids']\n",
    "    \n",
    "    # Check if the probas and qids values exist\n",
    "    if (len(probabilities) == 0 or len(qids) == 0):\n",
    "        return\n",
    "    \n",
    "    # Check if the speaker is not 'Unknown'\n",
    "    if (probabilities[0][0] == 'None'):\n",
    "        return\n",
    "    \n",
    "    # Check if the probability is over 80%\n",
    "    p = float(probabilities[0][1])\n",
    "    if (p < 0.8):\n",
    "        return\n",
    "    \n",
    "    # Check if the speaker is on the party list\n",
    "    qid = qids[0]\n",
    "    if qid not in party_list:\n",
    "        return\n",
    "    \n",
    "    # Remember only the quote and the probability\n",
    "    data = {}\n",
    "    data['quotation'] = row['quotation']\n",
    "    data['proba'] = row['probas'][0][1]\n",
    "    \n",
    "    # Append the quote\n",
    "    arr = party_member_quotes.get(qid, [])\n",
    "    arr.append(data)\n",
    "    party_member_quotes[qid] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b148349-766e-4001-b6a4-36414dd2a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join both party lists\n",
    "dem_and_rep_set = set()    \n",
    "for v in dem_list:\n",
    "    dem_and_rep_set.add(v['id'])\n",
    "for v in rep_list:\n",
    "    dem_and_rep_set.add(v['id'])\n",
    "\n",
    "# Define partial function check_if_dem_or_rep_quote using function check_if_party_member_quote\n",
    "check_if_dem_or_rep_quote = partial(check_if_party_member_quote, party_list=dem_and_rep_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee80d1f-1b4d-4b12-b480-b98be3534c4b",
   "metadata": {},
   "source": [
    "Create files for every year, each file contains a dictionary where the key is the QID of the speaker, and the value is the list of significant quotes attributed to the speaker.\n",
    "<br><br>\n",
    "<font color='red'>WARNING: LONG EXECUTION!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345886af-b87f-4c5d-b2dd-bdd0189ebfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
    "# years = [2020]\n",
    "\n",
    "output_list = []\n",
    "\n",
    "for year in years:\n",
    "    path_to_input = PATTERN_INPUT.format(year)\n",
    "    \n",
    "    # Process quote file\n",
    "    output_name = process_compressed_json_file(path_to_input, 'data/politician-quotes', year, check_if_dem_or_rep_quote)\n",
    "    \n",
    "    output_list.append(output_name)\n",
    "\n",
    "print('\\n\\nOutput file names:')\n",
    "for file_name in output_list:\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7ffd50-cad0-4be1-81f5-dae693471721",
   "metadata": {},
   "source": [
    "### Combine the quotes and the wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30180476-46c2-400d-a424-e9f7a0757a56",
   "metadata": {},
   "source": [
    "Now we combine the politician quotes with their wikidata information. We use the 6 files of politician quotes created in the previous step, as well as the list of the party members. The result is a file which contains 200 entries, where each entry represents one politician, and contains their wikidata info as well as a list of quotes. The list of quotes can be quite long for some of the politicians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1bacad-9fb3-407f-b6ba-1a4422135c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "poli_quote_files = [\n",
    "    \"../quotebank/politician-quotes-2015_1636331534906.json\",\n",
    "    \"../quotebank/politician-quotes-2016_1636332058163.json\",\n",
    "    \"../quotebank/politician-quotes-2017_1636333168732.json\",\n",
    "    \"../quotebank/politician-quotes-2018_1636334221167.json\",\n",
    "    \"../quotebank/politician-quotes-2019_1636335010497.json\",\n",
    "    \"../quotebank/politician-quotes-2020_1636330658142.json\"\n",
    "]\n",
    "\n",
    "poli_quotes_combined = {}\n",
    "\n",
    "both_parties = dem_list + rep_list\n",
    "for v in both_parties:\n",
    "    copy = dict(v)\n",
    "    copy['quotations'] = []\n",
    "    \n",
    "    poli_quotes_combined[v['id']] = copy\n",
    "\n",
    "for poli_quote_file_name in poli_quote_files:\n",
    "    with open(poli_quote_file_name, 'r') as f:\n",
    "        quotes = json.load(f)\n",
    "        \n",
    "        for k in quotes.keys():\n",
    "            poli_quotes_combined[k]['quotations'] += quotes[k]\n",
    "\n",
    "write_json_to_file('data/politician-quotes-combined', poli_quotes_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3147ad-1297-4bf9-a60b-fde7fe4bb168",
   "metadata": {},
   "source": [
    "### Filter the quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e2f8a-7e2d-45f9-b283-db99cceb3db2",
   "metadata": {},
   "source": [
    "Some of the quotes in the database do not represent actual quotes, but instead contain junk like html tags, source code, or text from the webpage where the source article was published.\n",
    "<br>\n",
    "We filter these quotes out so our dataset is not polluted by junk data. We have found a few filters which detect most of the junk data, while maintaining a low false positive rate:\n",
    "<ul>\n",
    "    <li>quotes which contains very long 'words' - more than 50 characters</li>\n",
    "    <li>quotes which contain URLs - these usually contain other junk characters</li>\n",
    "    <li>quotes which contains JSON-like key-value pairs</li>\n",
    "    <li>quotes which contain a lot of special characters (more than 10% of total characters)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e49ed80f-0a0d-4ead-9beb-8b5447e527fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../quotebank/politician-quotes-combined_1636336204264.json', 'r') as f:\n",
    "    poli_quotes_filtered = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca6885b3-4f20-46f4-96c5-0eb4c6ef923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_quotes = []\n",
    "\n",
    "weird_pattern = '[_@#+&;:\\(\\)\\{\\}\\[\\]\\\\/`]'\n",
    "json_pattern = '\\{.*[a-zA-Z]+:\\s[\\'\"`][a-zA-Z0-9]+[\\'\"`].*\\}'\n",
    "url_pattern = 'https?'\n",
    "\n",
    "for k in poli_quotes_filtered.keys():\n",
    "    elem = poli_quotes_filtered[k]\n",
    "    \n",
    "    new_arr = []\n",
    "    for entry in elem['quotations']:\n",
    "        text = entry['quotation']\n",
    "        \n",
    "        longest = max(entry['quotation'].split(), key=len)\n",
    "        if (len(longest) > 50):\n",
    "            filtered_quotes.append(entry)\n",
    "            continue\n",
    "        \n",
    "        if re.search(url_pattern, text) is not None:\n",
    "            filtered_quotes.append(entry)\n",
    "            continue\n",
    "        \n",
    "        if re.search(json_pattern, text) is not None:\n",
    "            filtered_quotes.append(entry)\n",
    "            continue\n",
    "            \n",
    "        weird_num = len(re.findall(weird_pattern, text))\n",
    "        total = len(text)\n",
    "        weird_percent = weird_num / total\n",
    "        if (weird_percent > 0.1):\n",
    "            filtered_quotes.append(entry)\n",
    "            continue\n",
    "            \n",
    "        new_arr.append(entry)\n",
    "    elem['quotations'] = new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a3ed2bb-4806-452b-931d-df96cc058994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/politician-quotes-combined-and-filtered_1636658577375.json'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_json_to_file('data/politician-quotes-combined-and-filtered', poli_quotes_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0d4cc-0b59-4085-b656-464f854658ba",
   "metadata": {},
   "source": [
    "Show some filtered quotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f95c3ebf-5668-48a6-b23f-30808470c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't guar & shy; an & shy; tee the ac & shy; tions of every single Amer & shy; ic & shy; an.\n",
      "\n",
      "I cannot Wed, 19 Mar 2014... http://es.pn/OuwyAO TODAY AT THE WHITE HOUSE: This afternoon President Obama hosts a screening of the new film\n",
      "\n",
      "one drop of 0 + / 0 -) blood\n",
      "\n",
      "I'm not ex & shy; ag & shy; ger & shy; at & shy; ing. I've been count & shy; ing. We'd be in mil & shy; it & shy; ary ac & shy; tions in sev & shy; en places around the world.\n",
      "\n",
      "This is one of the most incredible collections of mammoth fossils anywhere in the country. & hellip;' ); ua_tw_60081. setTitle (formatTweet (`Obama signs Waco Mammoth National Monument declaration' )); ua_tw_60081. addMediaItem (image60081); var params_60081 = {userAction: ua_60081, replyUserAction: ua_60081, cssPrefix:' #gig - div-buttons-60081-top' , shareButtons: [ {provider: `Facebook' , enableCount: `false' , iconOnly: `true' , iconImgUp: `data: image/svg + xml; base64, PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAxNy4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI + DQo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkxheWVyXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB2aWV3Qm94PSIwIDAgMTIwMCAzMzMiIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDEyMDAgMzMzIiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnIGlkPSJMYXllcl8yIj4NCgk8cmVjdCBmaWxsPSIjM0I1NzlCIiB3aWR0aD0iMTIwMCIgaGVpZ2h0PSIzMzMiLz4NCjwvZz4NCjxwYXRoIGZpbGw9IiNGRkZGRkYiIGQ9Ik0xODMuMSwyNDkuOGgtMzEuNHYtODMuMmgtMjF2LTI5aDIxdi0xNi42YzAtMjMuNCw2LjItMzcuNiwzMy45LTM3LjZoMjIuOHYyOWgtMTQuMg0KCWMtMTAuNSwwLTExLjEsNC4zLTExLjEsMTEuN3YxNC4yaDI1LjlsLTMuNywyOC40aC0yMi44TDE4My4xLDI0OS44TDE4My4xLDI0OS44eiIvPg0KPGcgaWQ9ImR2MExFSl8xXyIgZGlzcGxheT0ibm9uZSI + DQo8L2c + DQo8L3N2Zz4NCg = =' }, {provider: `Twitter' , userAction: ua_tw_60081, enableCount: `false' , iconOnly: `true' , iconImgUp: `data: image/svg + xml; base64, PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAxNy4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI + DQo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkxheWVyXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB2aWV3Qm94PSItMTgwIDAgMTIwMCAzMzMiIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgLTE4MCAwIDEyMDAgMzMzIiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxyZWN0IHg9Ii0xODAiIGZpbGw9IiM1NUFCRjEiIHdpZHRoPSIxMjAwIiBoZWlnaHQ9IjMzMyIvPg0KPHBhdGggZmlsbD0iI0ZGRkZGRiIgZD0iTTc5LjYsMTA3LjljLTYuOCwzLjEtMTQuMiw0LjktMjIuMiw2LjJjOC00LjksMTQuMi0xMi4zLDE3LjMtMjEuNmMtNy40LDQuMy0xNiw3LjQtMjQuNyw5LjINCgljLTYuOC03LjQtMTcuMy0xMi4zLTI4LjQtMTIuM2MtMjEuNiwwLTM4LjksMTcuMy0zOC45LDM4LjhjMCwzLjEsMC42LDYuMiwxLjIsOC42Yy0zMi4xLTEuOC02MS0xNy4zLTgwLjItNDAuNw0KCWMtMy4xLDUuNS01LjUsMTIuMy01LjUsMTkuN2MwLDEzLjYsNi44LDI1LjMsMTcuMywzMi4xYy02LjIsMC0xMi4zLTEuOS0xNy45LTQuOXYwLjZjMCwxOS4xLDEzLjYsMzQuNSwzMS40LDM4LjINCgljLTMuMSwwLjYtNi44LDEuMi0xMC41LDEuMmMtMi41LDAtNC45LDAtNy40LTAuNmM0LjksMTUuNCwxOS4xLDI2LjUsMzYuNCwyNy4xYy0xMy42LDEwLjUtMzAuMiwxNi42LTQ4LjEsMTYuNg0KCWMtMy4xLDAtNi4yLDAtOS4yLTAuNmMxNy4zLDExLjEsMzcuNiwxNy4zLDU5LjgsMTcuM2M3MS41LDAsMTEwLjQtNTkuMiwxMTAuNC0xMTAuNGMwLTEuOCwwLTMuMSwwLTQuOQ0KCUM2Ny45LDEyMi4xLDc0LjEsMTE1LjMsNzkuNiwxMDcuOXoiLz4NCjwvc3ZnPg0K' }, {provider:'Em ail' , enableCount: `false' , iconOnly: `true' , iconImgUp: `data: image/svg + xml; base64, PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4NCjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAxNy4xLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4NCjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI + DQo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkxheWVyXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB2aWV3Qm94PSIwIDAgMTIwMCAzMzMiIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDEyMDAgMzMzIiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxyZWN0IGZpbGw9IiNGNzk0MDAiIHdpZHRoPSIxMjAwIiBoZWlnaHQ9IjMzMyIvPg0KPHBhdGggZmlsbD0iI0ZGRkZGRiIgZD0iTTI2MC4yLDg1LjdINzIuOGMtNy40LDAtMTMuNiw2LjItMTMuNiwxMy42djEzNC40YzAsNy40LDYuMiwxMy42LDEzLjYsMTMuNmgxODguMWM3LjQsMCwxMy42LTYuMiwxMy42LTEzLjYNCglWOTkuM0MyNzMuOCw5MS45LDI2Ny42LDg1LjcsMjYwLjIsODUuN3ogTTIzMy43LDExMi45bC02Ny4yLDUzLjZsLTY3LjItNTMuNkgyMzMuN0wyMzMuNywxMTIuOXogTTI0Ny4zLDIyMC4ySDg1Ljd2LTkzLjdsODAuOCw2Ny4yDQoJbDgwLjgtNjcuMlYyMjAuMnoiLz4NCjwvc3ZnPg0K' } ], / / list of providers emailBody: `Hi, I \\'ve sent you this story from The Dallas Morning News: $URL$ $userMsg $$title $$sender $', containerID: `gig-div-buttons-60081-top' , cid:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entry in filtered_quotes[0:5]:\n",
    "    print(entry['quotation'], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29ea8c3-b33e-4988-a18c-c26c871cd41b",
   "metadata": {},
   "source": [
    "### Concatenate the quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c179925a-2e23-4a98-91e0-1c5845426efc",
   "metadata": {},
   "source": [
    "Finally, we concatenate the quotes into a single fixed-length string. We do this because of the limitation of the CSV file format, which can contains at most ~32000 characters in a single field. This means that most of the quotes will not be used.\n",
    "<br>\n",
    "Alternatively, we could use multiple fields for the same speaker, but we think the amount of characters that can fit in a single cell is enough for a decent analysis.\n",
    "<br>\n",
    "We sort the quotes by length and use the longest ones first. We do this because the longer quotes are a better representation of a person's speach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4156eae2-9288-477d-bdb9-258de315a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/politician-quotes-combined-and-filtered_1636577222699.json', 'r') as f:\n",
    "    poli_quotes_concat = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a02ee34d-512c-4ce3-8fbf-1a52ad915c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUOTE_LENGTH = 5000\n",
    "\n",
    "for k in poli_quotes_concat.keys():\n",
    "    elem = poli_quotes_concat[k]\n",
    "    \n",
    "    # Sort the quotes by length\n",
    "    elem['quotations'].sort(key = lambda x: len(x['quotation']), reverse = True)\n",
    "    \n",
    "    concat = ''\n",
    "    for quote in elem['quotations']:\n",
    "        # Concatenate the quotes\n",
    "        concat += ' ' + quote['quotation']\n",
    "        \n",
    "        # Trim if we are over QUOTE_LENGTH\n",
    "        if (len(concat) >= QUOTE_LENGTH):\n",
    "            concat = concat[0:QUOTE_LENGTH]\n",
    "            break\n",
    "    \n",
    "    elem['quotations'] = concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42d600af-93ec-400f-bbf1-b9442ca1bd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/politician-quotes-concatenated_1636658608415.json'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_json_to_file('data/politician-quotes-concatenated', poli_quotes_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "95865cb9-3c6b-4357-8071-5cf3560125ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>itemLabel</th>\n",
       "      <th>genderLabel</th>\n",
       "      <th>citizenshipLabel</th>\n",
       "      <th>languageLabel</th>\n",
       "      <th>religionLabel</th>\n",
       "      <th>ethnicLabel</th>\n",
       "      <th>degreeLabel</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>placeOfBirthLabel</th>\n",
       "      <th>memberOfParty</th>\n",
       "      <th>memberOfPartyLabel</th>\n",
       "      <th>quotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q76</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>male</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>[Congregationalist polity, United Church of Ch...</td>\n",
       "      <td>African Americans</td>\n",
       "      <td>[Bachelor of Arts, Juris Doctor]</td>\n",
       "      <td>1961-08-04T00:00:00Z</td>\n",
       "      <td>Kapiolani Medical Center for Women and Children</td>\n",
       "      <td>http://www.wikidata.org/entity/Q29552</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>Namaste! Thank you Prime Minister Modi for yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q6294</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>female</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Methodism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Juris Doctor, bachelor's degree]</td>\n",
       "      <td>1947-10-26T00:00:00Z</td>\n",
       "      <td>Edgewater Hospital</td>\n",
       "      <td>http://www.wikidata.org/entity/Q29552</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>Donors in Saudi Arabia constitute the most si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q359442</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>male</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Judaism</td>\n",
       "      <td>Jewish people</td>\n",
       "      <td>Bachelor of Arts</td>\n",
       "      <td>1941-09-08T00:00:00Z</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>[http://www.wikidata.org/entity/Q327591, http:...</td>\n",
       "      <td>[independent politician, Liberty Union Party, ...</td>\n",
       "      <td>Look, many of Trump's supporters are working-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q170581</td>\n",
       "      <td>Nancy Pelosi</td>\n",
       "      <td>female</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholicism</td>\n",
       "      <td>Italian American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940-03-26T00:00:00Z</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>http://www.wikidata.org/entity/Q29552</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>Good evening. I appreciate the opportunity to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q11673</td>\n",
       "      <td>Andrew Cuomo</td>\n",
       "      <td>male</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholicism</td>\n",
       "      <td>Italian American</td>\n",
       "      <td>Juris Doctor</td>\n",
       "      <td>1957-12-06T00:00:00Z</td>\n",
       "      <td>Queens</td>\n",
       "      <td>http://www.wikidata.org/entity/Q29552</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>Late last night, the Senate passed a tax bill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item        itemLabel genderLabel          citizenshipLabel  \\\n",
       "0      Q76     Barack Obama        male  United States of America   \n",
       "1    Q6294  Hillary Clinton      female  United States of America   \n",
       "2  Q359442   Bernie Sanders        male  United States of America   \n",
       "3  Q170581     Nancy Pelosi      female  United States of America   \n",
       "4   Q11673     Andrew Cuomo        male  United States of America   \n",
       "\n",
       "  languageLabel                                      religionLabel  \\\n",
       "0       English  [Congregationalist polity, United Church of Ch...   \n",
       "1       English                                          Methodism   \n",
       "2       English                                            Judaism   \n",
       "3       English                                        Catholicism   \n",
       "4       English                                        Catholicism   \n",
       "\n",
       "         ethnicLabel                        degreeLabel           dateOfBirth  \\\n",
       "0  African Americans   [Bachelor of Arts, Juris Doctor]  1961-08-04T00:00:00Z   \n",
       "1                NaN  [Juris Doctor, bachelor's degree]  1947-10-26T00:00:00Z   \n",
       "2      Jewish people                   Bachelor of Arts  1941-09-08T00:00:00Z   \n",
       "3   Italian American                                NaN  1940-03-26T00:00:00Z   \n",
       "4   Italian American                       Juris Doctor  1957-12-06T00:00:00Z   \n",
       "\n",
       "                                 placeOfBirthLabel  \\\n",
       "0  Kapiolani Medical Center for Women and Children   \n",
       "1                               Edgewater Hospital   \n",
       "2                                         Brooklyn   \n",
       "3                                        Baltimore   \n",
       "4                                           Queens   \n",
       "\n",
       "                                       memberOfParty  \\\n",
       "0              http://www.wikidata.org/entity/Q29552   \n",
       "1              http://www.wikidata.org/entity/Q29552   \n",
       "2  [http://www.wikidata.org/entity/Q327591, http:...   \n",
       "3              http://www.wikidata.org/entity/Q29552   \n",
       "4              http://www.wikidata.org/entity/Q29552   \n",
       "\n",
       "                                  memberOfPartyLabel  \\\n",
       "0                                   Democratic Party   \n",
       "1                                   Democratic Party   \n",
       "2  [independent politician, Liberty Union Party, ...   \n",
       "3                                   Democratic Party   \n",
       "4                                   Democratic Party   \n",
       "\n",
       "                                          quotations  \n",
       "0   Namaste! Thank you Prime Minister Modi for yo...  \n",
       "1   Donors in Saudi Arabia constitute the most si...  \n",
       "2   Look, many of Trump's supporters are working-...  \n",
       "3   Good evening. I appreciate the opportunity to...  \n",
       "4   Late last night, the Senate passed a tax bill...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(poli_quotes_concat.values()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ead77e",
   "metadata": {},
   "source": [
    "## Initial Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b58705c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdaee992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the concatenated quotes for top 100 politician\n",
    "with open('./data/politician-quotes-concatenated_1636411537251.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c597066",
   "metadata": {},
   "source": [
    "After getting the data, we extract the quote ID and the concatenated quote of each politician, and write them to `input_data1.csv` for the LIWC personality analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06aaf991",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_data1.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"qid\", \"quote\"])\n",
    "    for qid, all_value in data.items():\n",
    "        quote = all_value[\"quotations\"]\n",
    "        writer.writerow([qid, quote])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6959ee03",
   "metadata": {},
   "source": [
    "### LIWC Analysis\n",
    "After parsing the `input_data1.csv` using the liwc software (Academic Version), for each concatenated quote, it gains a list of features in terms of LIWC categories, such as pronoun, articles. We save the data as `output_data1.csv` and then load it to our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc = pd.read_csv('output_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2370b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source (A)</th>\n",
       "      <th>Source (B)</th>\n",
       "      <th>WC</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>I</th>\n",
       "      <th>We</th>\n",
       "      <th>Self</th>\n",
       "      <th>...</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Q1077594</td>\n",
       "      <td>The NCAA and collegiate sports more broadly n...</td>\n",
       "      <td>825</td>\n",
       "      <td>14.73</td>\n",
       "      <td>28.36</td>\n",
       "      <td>68.36</td>\n",
       "      <td>7.64</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source (A)                                         Source (B)   WC    WPS  \\\n",
       "12   Q1077594   The NCAA and collegiate sports more broadly n...  825  14.73   \n",
       "\n",
       "    Sixltr    Dic  Pronoun     I   We  Self  ...  Comma  Colon  SemiC  QMark  \\\n",
       "12   28.36  68.36     7.64  1.45  1.7  3.15  ...   2.79   0.12    0.0    0.0   \n",
       "\n",
       "    Exclam  Dash  Quote  Apostro  Parenth  OtherP  \n",
       "12     0.0  2.06    0.0     1.45      0.0    0.12  \n",
       "\n",
       "[1 rows x 86 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualise a random sample\n",
    "liwc.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0512840",
   "metadata": {},
   "source": [
    "### Personality Analysis Based on LIWC Results\n",
    "According to the research by Tal Yarkoni from University of Colorado at Boulder, significant correlations between LIWC categories and the big five personalities are identified based on a large scale analysis (2010). Hence, we create the `predict_personality()` function which interpret the correlation coefficients as scores and allows us to select the features based on the recorded significant level from the research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e90f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import LIWC_OCEAN_MAP\n",
    "\n",
    "def predict_personality(liwc_data: pd.DataFrame, sig_level: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"Predicts personality based on the LIWC metrics.\n",
    "    This function computes personality scores based on the LIWC features. It essentially multiplies the matrix of normalized LIWC\n",
    "    features with the matrix of correlations between LIWC and Big-Five personality types. \n",
    "    \n",
    "    More specifically, here liwc_data is of dimension (N, D) where N is the number of samples (e.g. quotes for speakers) and\n",
    "    D is the number LIWC features/categories (e.g. first_person_pronoun, negation etc. full list of categories and their descriptions\n",
    "    can be found in the LIWC manual https://www.researchgate.net/publication/228650445_The_Development_and_Psychometric_Properties_of_LIWC2007)\n",
    "    The correlations matrix on the other hand is of dimensions (D, K) where K is the number of extended BigFive personality categories \n",
    "    (e.g. neuroticism, depression, friendliness etc.) The significance level of these correlations can be also customized using the\n",
    "    sig_level parameter which ranges between 0 and 3 where 0 means use all the correlations, 1 means use only those with p < 0.05,\n",
    "    2 means use those with p < 0.01 and 3 means use those with p < 0.001.\n",
    "\n",
    "    Args:\n",
    "        liwc_data (pd.DataFrame): LIWC metrics data\n",
    "        sig_level (int, optional): Significance level. Defaults to 1 (i.e. p < 0.05)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Personality scores\n",
    "    \"\"\"\n",
    "    # Load LIWC-OCEAN correlations matrix\n",
    "    liwc_ocean_data = pd.read_csv('data/LIWC_OCEAN.csv', index_col=0)\n",
    "\n",
    "    # Load significancy level matrix for LIWC-OCEAN (of the same dimension as the correlations matrix)\n",
    "    liwc_ocean_sig_data = pd.read_csv('data/LIWC_OCEAN_Significance.csv', index_col=0)\n",
    "\n",
    "    # Rename LIWC features data columns to match correlations index names\n",
    "    liwc_data = liwc_data[list(LIWC_OCEAN_MAP.keys())].rename(columns=LIWC_OCEAN_MAP)\n",
    "\n",
    "    # Normalize LIWC features to be between 0 and 1\n",
    "    liwc_data = liwc_data.div(liwc_data.sum(axis=1), axis=0)\n",
    "\n",
    "    # Verify that the column names and index names match for matrix multiplication\n",
    "    assert (liwc_ocean_data.index == liwc_data.columns).all()\n",
    "\n",
    "    # Filter correlations by significance level\n",
    "    liwc_ocean_data_with_sig = liwc_ocean_data * (liwc_ocean_sig_data >= sig_level).astype(int)\n",
    "\n",
    "    # Compute personality scores\n",
    "    return liwc_data.dot(liwc_ocean_data_with_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bde3c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality = predict_personality(liwc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b51fb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>hostility</th>\n",
       "      <th>depression</th>\n",
       "      <th>self_consciousness</th>\n",
       "      <th>immoderation</th>\n",
       "      <th>vulnerability</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>friendliness</th>\n",
       "      <th>gregariousness</th>\n",
       "      <th>...</th>\n",
       "      <th>cooperation</th>\n",
       "      <th>modesty</th>\n",
       "      <th>sympathy</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>self_efficacy</th>\n",
       "      <th>orderliness</th>\n",
       "      <th>dutifulness</th>\n",
       "      <th>achievement_striving</th>\n",
       "      <th>self_discipline</th>\n",
       "      <th>cautiousness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.920334</td>\n",
       "      <td>-0.038939</td>\n",
       "      <td>2.156352</td>\n",
       "      <td>-0.049568</td>\n",
       "      <td>0.14622</td>\n",
       "      <td>-0.185656</td>\n",
       "      <td>-0.397437</td>\n",
       "      <td>2.485448</td>\n",
       "      <td>3.972683</td>\n",
       "      <td>3.314592</td>\n",
       "      <td>...</td>\n",
       "      <td>3.109864</td>\n",
       "      <td>0.954405</td>\n",
       "      <td>2.603854</td>\n",
       "      <td>-1.471541</td>\n",
       "      <td>2.190921</td>\n",
       "      <td>0.337737</td>\n",
       "      <td>0.779478</td>\n",
       "      <td>-1.747988</td>\n",
       "      <td>-1.446806</td>\n",
       "      <td>0.423959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     neuroticism   anxiety  hostility  depression  self_consciousness  \\\n",
       "117     0.920334 -0.038939   2.156352   -0.049568             0.14622   \n",
       "\n",
       "     immoderation  vulnerability  extraversion  friendliness  gregariousness  \\\n",
       "117     -0.185656      -0.397437      2.485448      3.972683        3.314592   \n",
       "\n",
       "     ...  cooperation   modesty  sympathy  conscientiousness  self_efficacy  \\\n",
       "117  ...     3.109864  0.954405  2.603854          -1.471541       2.190921   \n",
       "\n",
       "     orderliness  dutifulness  achievement_striving  self_discipline  \\\n",
       "117     0.337737     0.779478             -1.747988        -1.446806   \n",
       "\n",
       "     cautiousness  \n",
       "117      0.423959  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fddb9e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source (A)</th>\n",
       "      <th>Source (B)</th>\n",
       "      <th>WC</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>I</th>\n",
       "      <th>We</th>\n",
       "      <th>Self</th>\n",
       "      <th>...</th>\n",
       "      <th>cooperation</th>\n",
       "      <th>modesty</th>\n",
       "      <th>sympathy</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>self_efficacy</th>\n",
       "      <th>orderliness</th>\n",
       "      <th>dutifulness</th>\n",
       "      <th>achievement_striving</th>\n",
       "      <th>self_discipline</th>\n",
       "      <th>cautiousness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Q934898</td>\n",
       "      <td>And I see my father. My father was just wipin...</td>\n",
       "      <td>969</td>\n",
       "      <td>17.3</td>\n",
       "      <td>10.42</td>\n",
       "      <td>85.86</td>\n",
       "      <td>15.58</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.82</td>\n",
       "      <td>7.84</td>\n",
       "      <td>...</td>\n",
       "      <td>1.246182</td>\n",
       "      <td>1.163683</td>\n",
       "      <td>1.270105</td>\n",
       "      <td>-1.796902</td>\n",
       "      <td>0.643346</td>\n",
       "      <td>0.97126</td>\n",
       "      <td>0.736629</td>\n",
       "      <td>-1.169705</td>\n",
       "      <td>-1.303115</td>\n",
       "      <td>-0.2487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source (A)                                         Source (B)   WC   WPS  \\\n",
       "51    Q934898   And I see my father. My father was just wipin...  969  17.3   \n",
       "\n",
       "    Sixltr    Dic  Pronoun     I    We  Self  ...  cooperation   modesty  \\\n",
       "51   10.42  85.86    15.58  4.02  3.82  7.84  ...     1.246182  1.163683   \n",
       "\n",
       "    sympathy  conscientiousness  self_efficacy  orderliness  dutifulness  \\\n",
       "51  1.270105          -1.796902       0.643346      0.97126     0.736629   \n",
       "\n",
       "    achievement_striving  self_discipline  cautiousness  \n",
       "51             -1.169705        -1.303115       -0.2487  \n",
       "\n",
       "[1 rows x 121 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat the liwc output to the personality result\n",
    "df1 = pd.concat([liwc, personality], axis=1)\n",
    "df1.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc5d2315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source (A)</th>\n",
       "      <th>Source (B)</th>\n",
       "      <th>WC</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>I</th>\n",
       "      <th>We</th>\n",
       "      <th>Self</th>\n",
       "      <th>...</th>\n",
       "      <th>citizenshipLabel</th>\n",
       "      <th>languageLabel</th>\n",
       "      <th>religionLabel</th>\n",
       "      <th>ethnicLabel</th>\n",
       "      <th>degreeLabel</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>placeOfBirthLabel</th>\n",
       "      <th>memberOfParty</th>\n",
       "      <th>memberOfPartyLabel</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Q16215328</td>\n",
       "      <td>A lot of good takeaways from this weekend. A ...</td>\n",
       "      <td>873</td>\n",
       "      <td>19.84</td>\n",
       "      <td>20.73</td>\n",
       "      <td>70.9</td>\n",
       "      <td>7.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.98</td>\n",
       "      <td>...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975-01-01T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.wikidata.org/entity/Q29552</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>dem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source (A)                                         Source (B)   WC    WPS  \\\n",
       "78  Q16215328   A lot of good takeaways from this weekend. A ...  873  19.84   \n",
       "\n",
       "    Sixltr   Dic  Pronoun     I    We  Self  ...          citizenshipLabel  \\\n",
       "78   20.73  70.9     7.22  0.34  2.63  2.98  ...  United States of America   \n",
       "\n",
       "    languageLabel  religionLabel  ethnicLabel  degreeLabel  \\\n",
       "78            NaN            NaN          NaN          NaN   \n",
       "\n",
       "             dateOfBirth  placeOfBirthLabel  \\\n",
       "78  1975-01-01T00:00:00Z                NaN   \n",
       "\n",
       "                            memberOfParty  memberOfPartyLabel  party  \n",
       "78  http://www.wikidata.org/entity/Q29552    Democratic Party    dem  \n",
       "\n",
       "[1 rows x 134 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the top 100 politician data, queried from wikidata, concat with current dataset.\n",
    "with open('./data/top100_politicians_by_party.json', 'r') as f:\n",
    "    data_top100 = json.load(f)\n",
    "\n",
    "dem_df = pd.DataFrame(data_top100[\"dem\"])\n",
    "rep_df = pd.DataFrame(data_top100[\"rep\"])\n",
    "dem_df['party'] = \"dem\"\n",
    "rep_df['party'] = \"rep\"\n",
    "politician_wiki = pd.concat([dem_df, rep_df])\n",
    "df2 = df1.merge(politician_wiki, left_on='Source (A)', right_on='item', how = \"left\")\n",
    "df2.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa4ee7",
   "metadata": {},
   "source": [
    "## Basic Analysis\n",
    "\n",
    "For this part, we use the programming language R to get better visualisation and embed the output in html from knitting the our Rmarkdown document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db5a5e",
   "metadata": {},
   "source": [
    "### Comparing the Personality of Politicians from Democratic and Republic Parties\n",
    "\n",
    "We compare each characteristic for democratic and republic politicians using Wilcoxon rank sum test, which tests whether top politicians from different parties have the equal medians for each attribute. The reason for choosing Wilcoxon rank sum over two sample t test is that we do not know the distribution of the characteristic values and Wilcoxon does not assume known distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "## R codes\n",
    "library(gtsummary)\n",
    "library(dplyr)\n",
    "df = read.csv(\"concats\")\n",
    "df_personality_party <-  df %>% select(c(87:121, 134)) # 87:121 contains all personalities, 123 is name, 134 is party\n",
    "df_personality_party %>% tbl_summary(by = party) %>% add_p()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ae26b",
   "metadata": {},
   "source": [
    "<img src=\"./data/my_table.png\" style=\"width: 500px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfc4e0a",
   "metadata": {},
   "source": [
    "The current result shows that the only significant differences are artistic_interests and emotionality, where democratic politicians have higher average artistic_interests and emotionality compared to republic politicians."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367934de",
   "metadata": {},
   "source": [
    "### Comparing Main Politicians in US Based on Their Personality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b997534",
   "metadata": {},
   "source": [
    "We use interactive heatmap in r to produce the following map. By clicking on the specific cell, you can see the value of each attribute for the person and compare it to other politicians. When a cell is blue, it means a positive value with regards to that attribute. When it is red, it gives a negative value for the correponding characteristic. We can compare the value of each cell easily by looking at the color gradient, i.e. the deeper the color, the larger the absolute value.\n",
    "\n",
    "Moreover, by selecting several cells, you are able to zoom in to see difference in details. To go back to the original view, please double click the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf21503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"600\"\n",
       "            src=\"./data/section-2.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe864781390>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notes: Interactive heatmap will show up once you run the following code chunk. It will not show up directly\n",
    "# on Github since it does not support interactive map.\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='./data/section-2.html', width=700, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac11df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## R codes\n",
    "library(d3heatmap)\n",
    "\n",
    "df2 <- df %>% select(c(123, 87:121))\n",
    "rownames(df2) <- df2$itemLabel\n",
    "df2 <- df2 %>% select(-itemLabel)\n",
    "\n",
    "df_several <- df2[c(\"Barack Obama\", \"Hillary Clinton\", \"Joe Biden\", \"Elizabeth Warren\", \"Andrew Cuomo\", \"Donald Trump\", \"Lindsey Graham\", \"George W. Bush\"),] \n",
    "rownames(df_several) <- c(\"B. Obama\", \"H. Clinton\", \"J. Biden\", \"E. Warren\", \"A. Cuomo\", \"D. Trump\", \"L. Graham\", \"G. W. Bush\")\n",
    "d3heatmap(scale(df_several), colors = \"RdYlBu\",\n",
    "          k_row = 4, # Number of groups in rows\n",
    "          k_col = 2, # Number of groups in columns\n",
    "          scale = \"column\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b586e",
   "metadata": {},
   "source": [
    "<img src=\"./data/heatmap.png\" style=\"width: 500px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8022b36",
   "metadata": {},
   "source": [
    "On the plot above, similar people will be scattered together. For example,\n",
    "- Barack Obama and George W. Bush have similar personalities based on their quotations. \n",
    "- Donald Trump and Lindsey Graham are quite close on most scales of personality. \n",
    "- Obama and Trump seem to have opposite personality.\n",
    "- A few more details: \n",
    "  - Trump has high depression and low orderliness\n",
    "  - Bush has high assertiveness, extraversion and low hostility, neuroticism, anxiety\n",
    "  - Obama has high emotionality\n",
    "  - Biden has high modesty, morality, trust, cautiousness and low excitement seeking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
